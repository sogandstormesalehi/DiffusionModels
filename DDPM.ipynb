{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrKSw_MEJjgQ",
        "outputId": "3567cc7c-734a-4694-eeb2-2bb7a9bb643f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting labml_nn\n",
            "  Downloading labml_nn-0.4.133-py3-none-any.whl (434 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 KB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from labml_nn) (0.14.1+cu116)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from labml_nn) (1.13.1+cu116)\n",
            "Collecting labml-helpers>=0.4.89\n",
            "  Downloading labml_helpers-0.4.89-py3-none-any.whl (24 kB)\n",
            "Collecting fairscale\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 KB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchtext in /usr/local/lib/python3.9/dist-packages (from labml_nn) (0.14.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from labml_nn) (1.22.4)\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting labml>=0.4.158\n",
            "  Downloading labml-0.4.161-py3-none-any.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 KB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from labml>=0.4.158->labml_nn) (6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->labml_nn) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchtext->labml_nn) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torchtext->labml_nn) (4.65.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->labml_nn) (8.4.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext->labml_nn) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext->labml_nn) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext->labml_nn) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchtext->labml_nn) (2.0.12)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: fairscale\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332130 sha256=996b811f94a1e29d3878bf22b3c15b68e388ecf304667fd992101688439ce96d\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/ea/7f/8f35af83599829bb4790bdc16949dd99aeeb62e9a1faf47d47\n",
            "Successfully built fairscale\n",
            "Installing collected packages: smmap, einops, gitdb, fairscale, gitpython, labml, labml-helpers, labml_nn\n",
            "Successfully installed einops-0.6.0 fairscale-0.4.13 gitdb-4.0.10 gitpython-3.1.31 labml-0.4.161 labml-helpers-0.4.89 labml_nn-0.4.133 smmap-5.0.0\n"
          ]
        }
      ],
      "source": [
        "%run UNet.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, Optional, List\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from labml_helpers.device import DeviceConfigs\n",
        "from labml.configs import BaseConfigs, option\n",
        "from labml import lab, tracker, experiment, monit\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "IxHnPyQ9KvpL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gather(consts, t):\n",
        "  c = consts.gather(-1, t)\n",
        "  return c.reshape(-1, 1, 1, 1)"
      ],
      "metadata": {
        "id": "il5lR-8N8TUx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DDPM:\n",
        "  def __init__(self, eps, steps, device):\n",
        "    super().__init__()\n",
        "    self.eps = eps\n",
        "    self.steps = steps\n",
        "    self.beta = torch.linspace(0.0001, 0.02, steps).to(device)\n",
        "    self.alpha = 1 - self.beta\n",
        "    self.alpha_bar = torch.cumprod(self.alpha, dim = 0)\n",
        "    self.sigma_2 = self.beta\n",
        "\n",
        "  def q_xt_given_x0(self, x0, t):\n",
        "    mean = gather(self.alpha_bar, t) ** 0.5 * x0\n",
        "    variance = 1 - gather(self.alpha_bar, t)\n",
        "    return mean, variance\n",
        "\n",
        "  def sample_from_q(self, x0, t, eps):\n",
        "    if eps is None:\n",
        "      eps = torch.randn_like(x0)\n",
        "    mean, variance = self.q_xt_given_x0(x0, t)\n",
        "    return mean + (variance ** 0.5) * eps\n",
        "\n",
        "  def sample_from_p(self, xt, t):\n",
        "    eps = self.eps(xt, t)\n",
        "    alpha_bar = gather(self.alpha_bar, t)\n",
        "    alpha = gather(self.alpha, t)\n",
        "    beta = 1 - alpha\n",
        "    coefficient = beta / (1 - alpha_bar) ** 0.5\n",
        "    mean = ((1 / alpha) ** 0.5) * (xt - coefficient * eps)\n",
        "    variance = gather(self.sigma_2, t)\n",
        "    eps_ = torch.randn(xt.shape, device = xt.device)\n",
        "    return mean + (variance ** 0.5) * eps_\n",
        "\n",
        "  def loss(self, x0, noise):\n",
        "    batch_size = x0.shape[0]\n",
        "    t = torch.randint(0, self.steps, (batch_size,), device = x0.device, dtype = torch.long)\n",
        "    if noise is None:\n",
        "      noise = torch.randn_like(x0)\n",
        "    xt = self.sample_from_q(x0, t, noise)\n",
        "    eps_model = self.eps(xt, t)\n",
        "    return F.mse_loss(noise, eps_model)"
      ],
      "metadata": {
        "id": "uiR284dH8qmb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Configs(BaseConfigs):\n",
        "  device: torch.device = DeviceConfigs()\n",
        "  epsilon_model: UNet\n",
        "  diffusion: DDPM\n",
        "  img_channels: int = 3\n",
        "  img_size: int = 32\n",
        "  n_channels: int = 64\n",
        "  ch_mults: List[int] = [1, 2, 2, 4]\n",
        "  has_attention: List[int] = [False, False, False, True]\n",
        "  n_steps: int = 1000\n",
        "  batch_size: int = 64\n",
        "  n_samples: int = 16\n",
        "  learning_rate: float = 2e-5\n",
        "  epochs: int = 1000\n",
        "  dataset: torch.utils.data.Dataset\n",
        "  data_loader: torch.utils.data.DataLoader\n",
        "  optimizer: torch.optim.Adam\n",
        "\n",
        "  def init(self):\n",
        "    self.epsilon_model = UNet(\n",
        "        image_channels = self.image_channels,\n",
        "        n_channels = self.n_channels,\n",
        "        ch_mults = self.ch_mults,\n",
        "        has_attention = self.has_attention\n",
        "    ).to(self.device)\n",
        "\n",
        "    self.diffusion = DDPM(\n",
        "        eps = self.epsilon_model,\n",
        "        steps = self.n_steps,\n",
        "        device = self.device\n",
        "    )\n",
        "\n",
        "    data_loader = torch.utils.data.DataLoader(self.dataset, self.batch_size, shuffle = True, pin_memory = True)\n",
        "    self.optimizer = torch.optim.Adam(self.epsilon_model.parameters(), lr=self.learning_rate)\n",
        "    print(\"parameters:\\n\" + str(self.epsilon_model.parameters()))\n",
        "    tracker.set_image(\"sample\", True)\n",
        "\n",
        "  def sample(self):\n",
        "    with torch.no_grad():\n",
        "      x = torch.randn([self.n_samples, self.img_channels, self.img_size, self.img_size], device = self.device)\n",
        "      for t_ in monit.iterate('Sample', self.n_steps):\n",
        "        t = self.n_steps - t_ - 1\n",
        "        x = self.diffusion.sample_from_p(x, x.new_full((self.n_samples,), t, dtype=torch.long))\n",
        "      tracker.save('sample', x)\n",
        "\n",
        "  def train(self):\n",
        "    for data in monit.iterate('Train', self.data_loader):\n",
        "      tracker.add_global_step()\n",
        "      data = data.to(self.device)\n",
        "      self.optimizer.zero_grad()\n",
        "      loss = self.diffusion.loss(data)\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "      tracker.save('loss', loss)\n",
        "  \n",
        "  def training_loop(self):\n",
        "    for _ in monit.loop(self.epochs):\n",
        "      self.train()\n",
        "      self.sample()\n",
        "      tracker.new_line()\n",
        "      experiment.save_checkpoint()"
      ],
      "metadata": {
        "id": "vcg2xs6sLeCC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import helper\n",
        "data_dir = '/data/celebA'\n",
        "helper.download_extract('celeba', data_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7_D1boYOSCR",
        "outputId": "c2588594-5e65-408d-dfdf-f6e9d6e97dfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading celeba: 1.44GB [00:19, 75.6MB/s]                            \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting celeba...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CelebADataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, image_size: int):\n",
        "    super().__init__()\n",
        "    folder = lab.get_data_path() / 'celebA'\n",
        "    self._files = [p for p in folder.glob(f'**/*.jpg')]\n",
        "    self._transform = torchvision.transforms.Compose([torchvision.transforms.Resize(image_size),torchvision.transforms.ToTensor(),])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._files)\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    img = Image.open(self._files[index])\n",
        "    return self._transform(img)\n",
        "\n",
        "  @option(Configs.dataset, 'CelebA')\n",
        "  def celeb_dataset(c: Configs):\n",
        "    return CelebADataset(c.image_size)"
      ],
      "metadata": {
        "id": "U2u4LuGcSJte"
      },
      "execution_count": 16,
      "outputs": []
    }
  ]
}