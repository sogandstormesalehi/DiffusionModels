{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B2GP9wEogFay",
    "outputId": "036f03a1-2da7-4405-cd7b-2ae219486588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting labml_nn\n",
      "  Downloading labml_nn-0.4.133-py3-none-any.whl (434 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchtext in /usr/local/lib/python3.8/dist-packages (from labml_nn) (0.14.1)\n",
      "Collecting einops\n",
      "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (from labml_nn) (0.14.1+cu116)\n",
      "Collecting labml-helpers>=0.4.89\n",
      "  Downloading labml_helpers-0.4.89-py3-none-any.whl (24 kB)\n",
      "Collecting labml>=0.4.158\n",
      "  Downloading labml-0.4.161-py3-none-any.whl (129 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.2/129.2 KB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from labml_nn) (1.13.1+cu116)\n",
      "Collecting fairscale\n",
      "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 KB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from labml_nn) (1.22.4)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from labml>=0.4.158->labml_nn) (6.0)\n",
      "Collecting gitpython\n",
      "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->labml_nn) (4.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext->labml_nn) (2.25.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext->labml_nn) (4.64.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision->labml_nn) (8.4.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext->labml_nn) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext->labml_nn) (2022.12.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext->labml_nn) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext->labml_nn) (1.26.14)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: fairscale\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332138 sha256=5224f61c01aebef0387d46aa76856b0521326e25b05ed870a91319d8aee044c8\n",
      "  Stored in directory: /root/.cache/pip/wheels/b8/02/9b/dc7d4ff5145afdd28f456dae6605a46619af0370eca30d8d7e\n",
      "Successfully built fairscale\n",
      "Installing collected packages: smmap, einops, gitdb, fairscale, gitpython, labml, labml-helpers, labml_nn\n",
      "Successfully installed einops-0.6.0 fairscale-0.4.13 gitdb-4.0.10 gitpython-3.1.31 labml-0.4.161 labml-helpers-0.4.89 labml_nn-0.4.133 smmap-5.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install labml_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "JdUQ2vDJz0gj"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional, Tuple, Union, List\n",
    "import torch\n",
    "from torch import nn\n",
    "from labml_helpers.module import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ewtfzC9m5P2s"
   },
   "outputs": [],
   "source": [
    "class Swish(Module):\n",
    "  def forward(self, x):#x⋅σ(x)\n",
    "    return x * torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qpv7aU6f-wG7"
   },
   "outputs": [],
   "source": [
    "class TimeEmbedding(nn.Module):\n",
    "\n",
    "  def __init__(self, n_channels):\n",
    "    super().__init__()\n",
    "    self.n_channels = n_channels\n",
    "    self.lin1 = nn.Linear(self.n_channels // 4, self.n_channels) \n",
    "    self.act = Swish()\n",
    "    self.lin2 = nn.Linear(self.n_channels, self.n_channels)\n",
    "\n",
    "  def forward(self, t: torch.Tensor):\n",
    "    half_dim = self.n_channels // 8\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, device = t.device) * -emb)\n",
    "    emb = t[:, None] * emb[None, :]\n",
    "    print(t[:, None])\n",
    "    print(emb[None, :])\n",
    "    emb = torch.cat((emb.sin(), emb.cos()), dim = 1)\n",
    "    emb = self.act(self.lin1(emb))\n",
    "    emb = self.lin2(emb)\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "L5P25GfeFn1A"
   },
   "outputs": [],
   "source": [
    "class ResidualBlock(Module): # two convolution layers with group normalization\n",
    "  def __init__(self, in_channels, out_channels, time_channels, n_groups = 32, dropout = 0.1): # n_groups = the number of groups for group normalization\n",
    "    super().__init__()\n",
    "    self.norm1 = nn.GroupNorm(n_groups, in_channels)\n",
    "    self.activation1 = Swish()\n",
    "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = (3, 3), padding=(1, 1))\n",
    "    self.norm2 = nn.GroupNorm(n_groups, out_channels)\n",
    "    self.activation2 = Swish()\n",
    "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = (3, 3), padding=(1, 1))\n",
    "    if in_channels != out_channels:\n",
    "      self.shortcut = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1))\n",
    "    else:\n",
    "      self.shortcut = nn.Identity()\n",
    "    self.time_emb = nn.Linear(time_channels, out_channels)\n",
    "    self.time_activation = Swish()\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "  def forward(self, x, t):\n",
    "    h = self.conv1(self.activation1(self.norm1(x)))\n",
    "    h += self.time_emb(self.time_activation(t))[:, :, None, None]\n",
    "    h = self.conv2(self.dropout(self.activation2(self.norm2(h))))\n",
    "    return h + self.shortcut(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "sewgeBEla2BZ"
   },
   "outputs": [],
   "source": [
    "class AttentionBlock(Module):\n",
    "  def __init__(self, n_channels, n_heads = 1, d_k = None, n_groups = 32):\n",
    "    super().__init__()\n",
    "    if d_k is None:\n",
    "      d_k = n_channels\n",
    "    self.norm = nn.GroupNorm(n_groups, n_channels)\n",
    "    self.projection = nn.Linear(n_channels, n_heads * d_k * 3)\n",
    "    self.output = nn.Linear(n_heads * d_k, n_channels)\n",
    "    self.scale = d_k ** -0.5\n",
    "    self.n_heads = n_heads\n",
    "    self.d_k = d_k\n",
    "\n",
    "  def forward(self, x, t = None):\n",
    "    batch_size, n_channels, height, width = x.shape\n",
    "    x = x.view(batch_size, n_channels, -1).permute(0, 2, 1)\n",
    "    query_key_value = self.projection(x).view(batch_size, -1, self.n_heads, 3 * self.d_k)\n",
    "    query, key, value = torch.chunk(query_key_value, 3, dim = -1)\n",
    "    attention = torch.einsum('bihd, bjhd -> bijh', query, key) * self.scale\n",
    "    attention = attention.softmax(dim = 2)\n",
    "    result = torch.einsum('bijh, bjhd -> bihd', attention, value)\n",
    "    result = result.view(batch_size, -1, self.n_heads * self.d_k)\n",
    "    result = self.output(result)\n",
    "    result += x # skip\n",
    "    result = result.permute(0, 2, 1).view(batch_size, n_channels, height, width)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "4gqPkDWfh7ON"
   },
   "outputs": [],
   "source": [
    "class DownBlock(Module):\n",
    "  def __init__(self, in_channels, out_channels, time_channels, attention):\n",
    "    super().__init__()\n",
    "    self.residual = ResidualBlock(in_channels, out_channels, time_channels)\n",
    "    if attention:\n",
    "      self.attention = AttentionBlock(out_channels)\n",
    "    else:\n",
    "      self.attention = nn.Identity()\n",
    "    \n",
    "  def forward(self, x, t):\n",
    "    x = self.residual(x, t)\n",
    "    x = self.attention(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "wBQ1yrGarxLY"
   },
   "outputs": [],
   "source": [
    "class UpBlock(Module):\n",
    "  def __init__(self, in_channels, out_channels, time_channels, attention):\n",
    "    super().__init__()\n",
    "    self.residual = ResidualBlock(in_channels + out_channels, out_channels, time_channels)\n",
    "    if attention:\n",
    "      self.attention = AttentionBlock(out_channels)\n",
    "    else:\n",
    "      self.attention = nn.Identity()\n",
    "    \n",
    "  def forward(self, x, t):\n",
    "    x = self.residual(x, t)\n",
    "    x = self.attention(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KudyIaM9sTUD"
   },
   "outputs": [],
   "source": [
    "class MiddleBlock(Module):\n",
    "  def __init__(self, n_channels, time_channels):\n",
    "    super().__init__()\n",
    "    self.first_res = ResidualBlock(n_channels, n_channels, time_channels)\n",
    "    self.attention = AttentionBlock(n_channels)\n",
    "    self.second_res = ResidualBlock(n_channels, n_channels, time_channels)\n",
    "\n",
    "  def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
    "    x = self.first_res(x, t)\n",
    "    x = self.attention(x)\n",
    "    x = self.second_res(x, t)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "A7O01l1rs4kj"
   },
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "  def __init__(self, n_channels):\n",
    "    super().__init__()\n",
    "    self.conv = nn.ConvTranspose2d(n_channels, n_channels, (4, 4), (2, 2), (1, 1))\n",
    "\n",
    "  def forward(self, x, t):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Cyhzwfrdv4ak"
   },
   "outputs": [],
   "source": [
    "class Downsample(nn.Module):\n",
    "  def __init__(self, n_channels):\n",
    "    super().__init__()\n",
    "    self.conv = nn.ConvTranspose2d(n_channels, n_channels, (3, 3), (2, 2), (1, 1))\n",
    "\n",
    "  def forward(self, x, t):\n",
    "    return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Kfpeem7uwNwY"
   },
   "outputs": [],
   "source": [
    "class UNet(Module):\n",
    "  def __init__(self, image_channels = 3, n_channels = 64, channels_per_res = (1, 2, 2, 4), has_attention = (False, False, True, True), n_blocks = 2):\n",
    "    super().__init__()\n",
    "    n_resolutions = len(channels_per_res)\n",
    "    self.image_projection = nn.Conv2d(image_channels, n_channels, kernel_size=(3, 3), padding=(1, 1))\n",
    "    self.time_embedding = TimeEmbedding(n_channels * 4)\n",
    "    down = []\n",
    "    out_channels = in_channels = n_channels\n",
    "    for i in range(n_resolutions):\n",
    "      out_channels = in_channels * channels_per_res[i]\n",
    "      for block in range(n_blocks):\n",
    "        down.append(DownBlock(in_channels, out_channels, n_channels * 4, has_attention[i]))\n",
    "        in_channels = out_channels\n",
    "      if i < n_resolutions - 1:\n",
    "        down.append(Downsample(in_channels))\n",
    "    self.down = nn.ModuleList(down)\n",
    "\n",
    "    self.middle = MiddleBlock(out_channels, n_channels * 4, )\n",
    "\n",
    "    up = []\n",
    "    in_channels = out_channels\n",
    "    for i in reversed(range(n_resolutions)):\n",
    "      out_channels = in_channels\n",
    "      for block in range(n_blocks):\n",
    "        up.append(UpBlock(in_channels, out_channels, n_channels * 4, has_attention[i]))\n",
    "      out_channels = in_channels // channels_per_res[i]\n",
    "      up.append(UpBlock(in_channels, out_channels, n_channels * 4, has_attention[i]))\n",
    "      in_channels = out_channels\n",
    "      if i > 0:\n",
    "        up.append(Upsample(in_channels))\n",
    "    self.up = nn.ModuleList(up)\n",
    "    self.activation = Swish()\n",
    "    self.norm = nn.GroupNorm(8, n_channels)\n",
    "    self.final = nn.Conv2d(in_channels, image_channels, kernel_size = (3, 3), padding = (1, 1))\n",
    "  \n",
    "  def forward(self, x, t):\n",
    "    t = self.time_embedding(t)\n",
    "    x = self.image_projection(x)\n",
    "    h = [x]\n",
    "    for m in self.down:\n",
    "      x = m(x, t)\n",
    "      h.append(x)\n",
    "    x = self.middle(x, t)\n",
    "    for m in self.up:\n",
    "      if isinstance(m, Upsample):\n",
    "        x = m(x, t)\n",
    "      else:\n",
    "        s = h.pop()\n",
    "        x = torch.cat((x, s), dim = 1)\n",
    "        x = m(x, t)\n",
    "    return self.final(self.activation(self.norm(x)))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
